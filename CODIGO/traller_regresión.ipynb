{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRERIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos\n",
    "Los datos están [acá](https://archive.ics.uci.edu/dataset/320/student+performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables para trabajar\n",
    "\n",
    "* studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n",
    "*  failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n",
    "* famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n",
    "* freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n",
    "* goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n",
    "* Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n",
    "* health - current health status (numeric: from 1 - very bad to 5 - very good)\n",
    "* absences - number of school absences (numeric: from 0 to 93)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener las características y los datos del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school_MS            float64\n",
      "sex_M                float64\n",
      "address_U            float64\n",
      "famsize_LE3          float64\n",
      "Pstatus_T            float64\n",
      "Mjob_health          float64\n",
      "Mjob_other           float64\n",
      "Mjob_services        float64\n",
      "Mjob_teacher         float64\n",
      "Fjob_health          float64\n",
      "Fjob_other           float64\n",
      "Fjob_services        float64\n",
      "Fjob_teacher         float64\n",
      "reason_home          float64\n",
      "reason_other         float64\n",
      "reason_reputation    float64\n",
      "guardian_mother      float64\n",
      "guardian_other       float64\n",
      "schoolsup_yes        float64\n",
      "famsup_yes           float64\n",
      "paid_yes             float64\n",
      "activities_yes       float64\n",
      "nursery_yes          float64\n",
      "higher_yes           float64\n",
      "internet_yes         float64\n",
      "romantic_yes         float64\n",
      "studytime            float64\n",
      "failures             float64\n",
      "absences             float64\n",
      "age                    int64\n",
      "Medu                   int64\n",
      "Fedu                   int64\n",
      "traveltime             int64\n",
      "famrel                 int64\n",
      "freetime               int64\n",
      "goout                  int64\n",
      "Dalc                   int64\n",
      "Walc                   int64\n",
      "health                 int64\n",
      "dtype: object\n",
      "Resultados para G1:\n",
      "MSE: 7.41\n",
      "R2 Score: 0.14\n",
      "------------------------------\n",
      "Resultados para G2:\n",
      "MSE: 7.98\n",
      "R2 Score: 0.11\n",
      "------------------------------\n",
      "Resultados para G3:\n",
      "MSE: 8.19\n",
      "R2 Score: 0.16\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# 1. Cargar los datos\n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "X = student_performance.data.features  # Características\n",
    "y = student_performance.data.targets   # Variables objetivo (notas)\n",
    "\n",
    "# 2. Definir columnas categóricas y numéricas\n",
    "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian',\n",
    "                    'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet','romantic']\n",
    "numeric_cols = ['studytime', 'failures', 'absences']\n",
    "\n",
    "# 3. Codificación de variables categóricas\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)  # drop='first' para evitar multicolinealidad\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# 4. Normalización de variables numéricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# 5. Unir las columnas codificadas y normalizadas con las demás columnas no categóricas\n",
    "X_preprocessed = pd.concat([X_encoded, X_scaled, X.drop(columns=categorical_cols + numeric_cols)], axis=1)\n",
    "\n",
    "# Verificar si quedan columnas de tipo object (categóricas no convertidas)\n",
    "print(X_preprocessed.dtypes)\n",
    "\n",
    "# 6. Separar las variables objetivo\n",
    "y1 = y['G1']\n",
    "y2 = y['G2']\n",
    "y3 = y['G3']\n",
    "\n",
    "# 7. Función para entrenar y evaluar regresión lineal\n",
    "def regresion_lineal(X, y_target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Crear el modelo de regresión lineal\n",
    "    modelo = LinearRegression()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Resultados para {y_target.name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 8. Realizar las regresiones para G1, G2 y G3\n",
    "regresion_lineal(X_preprocessed, y1)\n",
    "regresion_lineal(X_preprocessed, y2)\n",
    "regresion_lineal(X_preprocessed, y3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para G1:\n",
      "MSE: 7.03\n",
      "R2 Score: 0.18\n",
      "------------------------------\n",
      "Resultados para G2:\n",
      "MSE: 7.67\n",
      "R2 Score: 0.15\n",
      "------------------------------\n",
      "Resultados para G3:\n",
      "MSE: 8.11\n",
      "R2 Score: 0.17\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# 1. Cargar los datos\n",
    "student_performance = fetch_ucirepo(id=320)\n",
    "X = student_performance.data.features  # Características\n",
    "y = student_performance.data.targets   # Variables objetivo (notas)\n",
    "\n",
    "# 2. Definir columnas categóricas y numéricas\n",
    "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian',\n",
    "                    'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "numeric_cols = ['studytime', 'failures', 'absences']\n",
    "\n",
    "# 3. Codificación de variables categóricas\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# 4. Normalización de variables numéricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# 5. Unir las columnas codificadas y normalizadas\n",
    "X_preprocessed = pd.concat([X_encoded, X_scaled], axis=1)\n",
    "\n",
    "# 6. Separar las variables objetivo\n",
    "y1 = y['G1']\n",
    "y2 = y['G2']\n",
    "y3 = y['G3']\n",
    "\n",
    "# 7. Función para entrenar y evaluar regresión lineal con Ridge\n",
    "def regresion_lineal(X, y_target, alpha=1.0):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Modelo de Ridge\n",
    "    model = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Resultados para {y_target.name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 8. Realizar las regresiones para G1, G2 y G3\n",
    "regresion_lineal(X_preprocessed, y1, alpha=1.0)\n",
    "regresion_lineal(X_preprocessed, y2, alpha=1.0)\n",
    "regresion_lineal(X_preprocessed, y3, alpha=1.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para G1:\n",
      "MSE: 6.99\n",
      "R2 Score: 0.19\n",
      "------------------------------\n",
      "Resultados para G2:\n",
      "MSE: 7.36\n",
      "R2 Score: 0.18\n",
      "------------------------------\n",
      "Resultados para G3:\n",
      "MSE: 8.50\n",
      "R2 Score: 0.13\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# 1. Cargar los datos\n",
    "student_performance = fetch_ucirepo(id=320)\n",
    "X = student_performance.data.features  # Características\n",
    "y = student_performance.data.targets   # Variables objetivo (notas)\n",
    "\n",
    "# 2. Definir columnas categóricas y numéricas\n",
    "categorical_cols = ['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian',\n",
    "                    'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
    "numeric_cols = ['studytime', 'failures', 'absences']\n",
    "\n",
    "# 3. Codificación de variables categóricas\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]), columns=encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# 4. Normalización de variables numéricas\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
    "\n",
    "# 5. Unir las columnas codificadas y normalizadas\n",
    "X_preprocessed = pd.concat([X_encoded, X_scaled], axis=1)\n",
    "\n",
    "# 6. Separar las variables objetivo\n",
    "y1 = y['G1']\n",
    "y2 = y['G2']\n",
    "y3 = y['G3']\n",
    "\n",
    "# 7. Función para entrenar y evaluar el modelo de Random Forest\n",
    "def random_forest_regressor(X, y_target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Crear el modelo de Random Forest\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)  # Puedes ajustar n_estimators según sea necesario\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Métricas de evaluación\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Resultados para {y_target.name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.2f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 8. Realizar las regresiones para G1, G2 y G3\n",
    "random_forest_regressor(X_preprocessed, y1)\n",
    "random_forest_regressor(X_preprocessed, y2)\n",
    "random_forest_regressor(X_preprocessed, y3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 Model - MSE: 6.41, R²: 0.23\n",
      "G2 Model - MSE: 7.79, R²: 0.21\n",
      "G3 Model - MSE: 8.32, R²: 0.25\n",
      "G1 Random Forest Model - MSE: 6.68, R²: 0.20\n",
      "G2 Random Forest Model - MSE: 7.75, R²: 0.21\n",
      "G3 Random Forest Model - MSE: 8.24, R²: 0.26\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "student_performance = fetch_ucirepo(id=320)\n",
    "\n",
    "\n",
    "X = student_performance.data.features\n",
    "y = student_performance.data.targets\n",
    "\n",
    "\n",
    "X_dummies = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "G1 = y['G1']\n",
    "G2 = y['G2']\n",
    "G3 = y['G3']\n",
    "\n",
    "def fit_and_evaluate_model(target_variable, feature_data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_variable, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = Lasso(alpha=0.1) \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "# Store results\n",
    "results = {}\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    model, mse, r2 = fit_and_evaluate_model(target, X_dummies)\n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "# Optionally, try a Random Forest model as well\n",
    "def fit_random_forest(target_variable, feature_data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_variable, test_size=0.3, random_state=42)\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    model, mse, r2 = fit_random_forest(target, X_dummies)\n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Random Forest Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Correlación:\n",
      "                        age      Medu      Fedu  traveltime  studytime  failures    famrel  freetime     goout      Dalc      Walc    health  absences  school_MS     sex_M  address_U  famsize_LE3  Pstatus_T  Mjob_health  Mjob_other  Mjob_services  Mjob_teacher  Fjob_health  Fjob_other  Fjob_services  Fjob_teacher  reason_home  reason_other  reason_reputation  guardian_mother  guardian_other  schoolsup_yes  famsup_yes  paid_yes  activities_yes  nursery_yes  higher_yes  internet_yes  romantic_yes        G1        G2        G3\n",
      "age                1.000000 -0.107832 -0.121050    0.034490  -0.008415  0.319968 -0.020559 -0.004910  0.112805  0.134768  0.086357 -0.008750  0.149998   0.087170 -0.043662  -0.025848    -0.002470  -0.005631    -0.100237    0.038776      -0.034880     -0.046692    -0.103504    0.058406      -0.024570     -0.054154    -0.014716     -0.006385          -0.016565        -0.048726        0.330353      -0.167841   -0.101894 -0.005458       -0.054279    -0.021441   -0.265497      0.013115      0.178810 -0.174322 -0.107119 -0.106505\n",
      "Medu              -0.107832  1.000000  0.647477   -0.265079   0.097006 -0.172210  0.024421 -0.019686  0.009536 -0.007018 -0.019766  0.004614 -0.008577  -0.254787  0.119127   0.190320    -0.014325  -0.057174     0.261215   -0.224335       0.130272      0.449847     0.155576   -0.117551      -0.012576      0.258136     0.036580     -0.034855           0.132502         0.091562       -0.101123      -0.022168    0.120491  0.113973        0.119354     0.125951    0.213896      0.266052     -0.030992  0.260472  0.264035  0.240151\n",
      "Fedu              -0.121050  0.647477  1.000000   -0.208288   0.050400 -0.165915  0.020256  0.006841  0.027690  0.000061  0.038445  0.044910  0.029859  -0.209806  0.083913   0.141493    -0.039538  -0.031856     0.140789   -0.197974       0.104368      0.312130     0.227081   -0.216447       0.026575      0.348874     0.017710     -0.027127           0.085076        -0.044450       -0.066684       0.023572    0.135191  0.094628        0.079700     0.074863    0.191735      0.183483     -0.067675  0.217501  0.225139  0.211800\n",
      "traveltime         0.034490 -0.265079 -0.208288    1.000000  -0.063154  0.097730 -0.009521  0.000937  0.057454  0.092824  0.057007 -0.048261 -0.008149   0.252936  0.040880  -0.344902     0.012794   0.040633    -0.104606    0.034973      -0.072497     -0.097961    -0.089981    0.101121      -0.031740     -0.040209    -0.125946      0.059440          -0.076058        -0.066130        0.090497      -0.044807   -0.039289 -0.044842       -0.033376    -0.011509   -0.071958     -0.190826      0.004751 -0.154120 -0.154489 -0.127173\n",
      "studytime         -0.008415  0.097006  0.050400   -0.063154   1.000000 -0.147441 -0.004127 -0.068829 -0.075442 -0.137585 -0.214925 -0.056433 -0.118389  -0.137857 -0.206214   0.062023    -0.010945  -0.008748    -0.018978   -0.004220       0.029369      0.035469     0.096471   -0.035826       0.014716     -0.020335    -0.011796     -0.088833           0.179023        -0.018076        0.006440       0.089316    0.143509 -0.002314        0.070080     0.042630    0.188256      0.037529      0.033036  0.260875  0.240498  0.249789\n",
      "failures           0.319968 -0.172210 -0.165915    0.097730  -0.147441  1.000000 -0.062645  0.108995  0.045078  0.105949  0.082266  0.035588  0.122779   0.113788  0.073888  -0.063824    -0.066068  -0.009881    -0.016391   -0.001301       0.011652     -0.123945    -0.057688    0.044940      -0.006725     -0.079352    -0.080719      0.000204          -0.111185        -0.056527        0.234027      -0.000745   -0.006982  0.069416        0.000561    -0.069241   -0.309400     -0.095330      0.069901 -0.384210 -0.385782 -0.393316\n",
      "famrel            -0.020559  0.024421  0.020256   -0.009521  -0.004127 -0.062645  1.000000  0.129216  0.089707 -0.075767 -0.093511  0.109559 -0.089534  -0.031597  0.083473  -0.033897     0.004641   0.051303    -0.028803   -0.006960       0.037384     -0.000040     0.013917    0.017729       0.041555     -0.045845    -0.021748      0.015373           0.034705         0.012507       -0.067365      -0.012038    0.015228  0.031937        0.057597     0.041055    0.048239      0.082214     -0.044920  0.048795  0.089588  0.063361\n",
      "freetime          -0.004910 -0.019686  0.006841    0.000937  -0.068829  0.108995  0.129216  1.000000  0.346352  0.109904  0.120244  0.084526 -0.018716   0.034666  0.146305  -0.036647    -0.021257   0.037585    -0.020480   -0.019520       0.012552      0.060821    -0.024966    0.037996      -0.051132      0.003269    -0.055329     -0.032606          -0.009839         0.022349        0.033823      -0.015611    0.003764 -0.049574        0.150329    -0.007096   -0.102618      0.063268      0.027112 -0.094497 -0.106678 -0.122705\n",
      "goout              0.112805  0.009536  0.027690    0.057454  -0.075442  0.045078  0.089707  0.346352  1.000000  0.245126  0.388680 -0.015741  0.085374   0.044632  0.058178   0.015475    -0.004312   0.031086     0.040716    0.008832       0.044643     -0.055594     0.026582    0.040062      -0.027686     -0.038139    -0.014189      0.002870          -0.004559         0.042602        0.018432      -0.058124    0.017262 -0.006683        0.088582     0.018679   -0.069105      0.092869     -0.000520 -0.074053 -0.079469 -0.087641\n",
      "Dalc               0.134768 -0.007018  0.000061    0.092824  -0.137585  0.105949 -0.075767  0.109904  0.245126  1.000000  0.616561  0.059067  0.172952   0.047169  0.282696  -0.047304     0.060482   0.041513    -0.077160   -0.019067       0.056067      0.025662    -0.004988   -0.051626       0.089535     -0.022459     0.060085      0.121225          -0.091842        -0.093064        0.112437      -0.028076   -0.016844  0.051986        0.022592    -0.078376   -0.131663      0.042811      0.062042 -0.195171 -0.189480 -0.204719\n",
      "Walc               0.086357 -0.019766  0.038445    0.057007  -0.214925  0.082266 -0.093511  0.120244  0.388680  0.616561  1.000000  0.114988  0.156373   0.014169  0.320785  -0.012416     0.081958   0.070976     0.025412   -0.059740       0.049740      0.018384    -0.015909   -0.019179       0.102381     -0.084424     0.017744      0.060435          -0.026365        -0.006809       -0.002456      -0.098275   -0.065605  0.035682        0.032824    -0.075748   -0.084327      0.060651     -0.019971 -0.155649 -0.164852 -0.176619\n",
      "health            -0.008750  0.004614  0.044910   -0.048261  -0.056433  0.035588  0.109559  0.084526 -0.015741  0.059067  0.114988  1.000000 -0.030235  -0.058599  0.139547   0.003787     0.002448   0.012638     0.029586   -0.033425       0.070931      0.031889     0.096117    0.047775      -0.076209      0.017218    -0.025086      0.008124          -0.112359         0.009374        0.008833       0.022760    0.018803  0.063203        0.013001     0.001701    0.017290     -0.022792     -0.018025 -0.051647 -0.082179 -0.098851\n",
      "absences           0.149998 -0.008577  0.029859   -0.008149  -0.118389  0.122779 -0.089534 -0.018716  0.085374  0.172952  0.156373 -0.030235  1.000000  -0.163933  0.021336   0.073653     0.004645  -0.117492    -0.094786    0.026381       0.071283     -0.041773    -0.025463    0.026795      -0.035095     -0.017044     0.093812     -0.067165           0.017392         0.005036        0.155654      -0.059503    0.041980 -0.035959       -0.015115    -0.040574   -0.129891      0.067301      0.079489 -0.147149 -0.124745 -0.091379\n",
      "school_MS          0.087170 -0.254787 -0.209806    0.252936  -0.137857  0.113788 -0.031597  0.034666  0.044632  0.047169  0.014169 -0.058599 -0.163933   1.000000 -0.083050  -0.354520     0.022252   0.028120    -0.070628    0.040691      -0.122055     -0.103729    -0.052641   -0.063940       0.064697     -0.092356    -0.137548      0.205220          -0.162282        -0.052590       -0.016982      -0.123340   -0.063720 -0.007905       -0.088604     0.004659   -0.136112     -0.240486      0.072241 -0.292626 -0.269776 -0.284294\n",
      "sex_M             -0.043662  0.119127  0.083913    0.040880  -0.206214  0.073888  0.083473  0.146305  0.058178  0.282696  0.320785  0.139547  0.021336  -0.083050  1.000000   0.025503     0.098205   0.064700     0.039825   -0.023970       0.055879      0.104647    -0.007233   -0.034251       0.047612      0.044416     0.059079      0.034816          -0.027289        -0.030708       -0.010358      -0.111202   -0.129467  0.079300        0.124707    -0.043603   -0.058134      0.065911     -0.110144 -0.104109 -0.104005 -0.129077\n",
      "address_U         -0.025848  0.190320  0.141493   -0.344902   0.062023 -0.063824 -0.033897 -0.036647  0.015475 -0.047304 -0.012416  0.003787  0.073653  -0.354520  0.025503   1.000000     0.046113  -0.094635     0.084131   -0.038934       0.101131      0.073149     0.072167   -0.064898       0.014508      0.028221     0.161183     -0.086910          -0.012882         0.015464       -0.035192       0.017956    0.005577 -0.030483       -0.009278     0.018077    0.076706      0.175794     -0.030939  0.157127  0.154600  0.167637\n",
      "famsize_LE3       -0.002470 -0.014325 -0.039538    0.012794  -0.010945 -0.066068  0.004641 -0.021257 -0.004312  0.060482  0.081958  0.002448  0.004645   0.022252  0.098205   0.046113     1.000000  -0.239608     0.010316   -0.057439       0.022942      0.039768     0.021832    0.016528       0.003410     -0.083334     0.023438     -0.046227           0.046385         0.017646       -0.015673      -0.056405   -0.039819 -0.050253       -0.014790     0.100686    0.004523      0.013357     -0.032936  0.047230  0.038891  0.045016\n",
      "Pstatus_T         -0.005631 -0.057174 -0.031856    0.040633  -0.008748 -0.009881  0.051303  0.037585  0.031086  0.041513  0.070976  0.012638 -0.117492   0.028120  0.064700  -0.094635    -0.239608   1.000000     0.016419   -0.030621      -0.037264      0.027986    -0.004180   -0.073386       0.097317     -0.011516    -0.040492      0.042910          -0.038142        -0.070786       -0.114559      -0.009456    0.010203  0.015923        0.101555    -0.032724    0.022726      0.059754     -0.053828  0.015251  0.018689 -0.000754\n",
      "Mjob_health       -0.100237  0.261215  0.140789   -0.104606  -0.018978 -0.016391 -0.028803 -0.020480  0.040716 -0.077160  0.025412  0.029586 -0.094786  -0.070628  0.039825   0.084131     0.010316   0.016419     1.000000   -0.229565      -0.145510     -0.099830     0.232431   -0.072968       0.021180     -0.017042    -0.028279      0.031399           0.105455        -0.034105       -0.049186      -0.058235    0.043086  0.002863        0.008277     0.036501    0.097475      0.085946      0.016156  0.102689  0.104420  0.101244\n",
      "Mjob_other         0.038776 -0.224335 -0.197974    0.034973  -0.004220 -0.001301 -0.006960 -0.019520  0.008832 -0.019067 -0.059740 -0.033425  0.026381   0.040691 -0.023970  -0.038934    -0.057439  -0.030621    -0.229565    1.000000      -0.418246     -0.286946    -0.104616    0.235678      -0.154132     -0.086812     0.080608     -0.046341           0.008755        -0.109205        0.086726       0.040788   -0.091924 -0.033171       -0.077004    -0.087954   -0.026252     -0.066857      0.039095 -0.036684 -0.040108 -0.059251\n",
      "Mjob_services     -0.034880  0.130272  0.104368   -0.072497   0.029369  0.011652  0.037384  0.012552  0.044643  0.056067  0.049740  0.070931  0.071283  -0.122055  0.055879   0.101131     0.022942  -0.037264    -0.145510   -0.418246       1.000000     -0.181882    -0.016785   -0.144397       0.177884      0.007544    -0.020015     -0.001059           0.064249         0.063294       -0.087019       0.046361    0.074613  0.045041        0.060531     0.026858    0.042486      0.149119     -0.063447  0.039645  0.026613  0.038447\n",
      "Mjob_teacher      -0.046692  0.449847  0.312130   -0.097961   0.035469 -0.123945 -0.000040  0.060821 -0.055594  0.025662  0.018384  0.031889 -0.041773  -0.103729  0.104647   0.073149     0.039768   0.027986    -0.099830   -0.286946      -0.181882      1.000000     0.064971   -0.125848       0.010064      0.257344     0.017148     -0.031051          -0.022069         0.123488       -0.051397      -0.056772    0.028670 -0.006743        0.098696     0.076450    0.105923      0.148069     -0.045922  0.148925  0.136419  0.134910\n",
      "Fjob_health       -0.103504  0.155576  0.227081   -0.089981   0.096471 -0.057688  0.013917 -0.024966  0.026582 -0.004988 -0.015909  0.096117 -0.025463  -0.052641 -0.007233   0.072167     0.021832  -0.004180     0.232431   -0.104616      -0.016785      0.064971     1.000000   -0.218668      -0.119205     -0.046451    -0.045189      0.064971           0.079065        -0.038682       -0.049776       0.070481    0.083770 -0.013400       -0.002723     0.053120    0.039076      0.006929     -0.025398  0.045028  0.045478  0.039142\n",
      "Fjob_other         0.058406 -0.117551 -0.216447    0.101121  -0.035826  0.044940  0.017729  0.037996  0.040062 -0.051626 -0.019179  0.047775  0.026795  -0.063940 -0.034251  -0.064898     0.016528  -0.073386    -0.072968    0.235678      -0.144397     -0.125848    -0.218668    1.000000      -0.709455     -0.276458     0.064618     -0.086258           0.016016         0.086263        0.087079      -0.014747   -0.064231  0.012374       -0.062991    -0.020451   -0.019982      0.002857      0.005471 -0.015253 -0.010922 -0.005301\n",
      "Fjob_services     -0.024570 -0.012576  0.026575   -0.031740   0.014716 -0.006725  0.041555 -0.051132 -0.027686  0.089535  0.102381 -0.076209 -0.035095   0.064697  0.047612   0.014508     0.003410   0.097317     0.021180   -0.154132       0.177884      0.010064    -0.119205   -0.709455       1.000000     -0.150708    -0.037210      0.075705          -0.015596        -0.059257       -0.062630      -0.055696   -0.007044  0.001782        0.035401    -0.011243    0.025007      0.049705     -0.018912 -0.024090 -0.042709 -0.053204\n",
      "Fjob_teacher      -0.054154  0.258136  0.348874   -0.040209  -0.020335 -0.079352 -0.045845  0.003269 -0.038139 -0.022459 -0.084424  0.017218 -0.017044  -0.092356  0.044416   0.028221    -0.083334  -0.011516    -0.017042   -0.086812       0.007544      0.257344    -0.046451   -0.276458      -0.150708      1.000000    -0.004242      0.021566           0.001101        -0.003512       -0.062930       0.070951    0.026580 -0.032951        0.034036    -0.015223    0.061747      0.005990      0.024321  0.146338  0.146767  0.125916\n",
      "reason_home       -0.014716  0.036580  0.017710   -0.125946  -0.011796 -0.080719 -0.021748 -0.055329 -0.014189  0.060085  0.017744 -0.025086  0.093812  -0.137548  0.059079   0.161183     0.023438  -0.040492    -0.028279    0.080608      -0.020015      0.017148    -0.045189    0.064618      -0.037210     -0.004242     1.000000     -0.192835          -0.290202         0.004316        0.023901       0.052495    0.027275  0.062376       -0.082974    -0.024062    0.045657      0.066481      0.000983  0.051471  0.040337  0.046537\n",
      "reason_other      -0.006385 -0.034855 -0.027127    0.059440  -0.088833  0.000204  0.015373 -0.032606  0.002870  0.121225  0.060435  0.008124 -0.067165   0.205220  0.034816  -0.086910    -0.046227   0.042910     0.031399   -0.046341      -0.001059     -0.031051     0.064971   -0.086258       0.075705      0.021566    -0.192835      1.000000          -0.187789         0.016315       -0.071564       0.007306   -0.092220  0.034544       -0.087820     0.002470   -0.053244     -0.049326      0.035453 -0.090738 -0.096135 -0.132577\n",
      "reason_reputation -0.016565  0.132502  0.085076   -0.076058   0.179023 -0.111185  0.034705 -0.009839 -0.004559 -0.091842 -0.026365 -0.112359  0.017392  -0.162282 -0.027289  -0.012882     0.046385  -0.038142     0.105455    0.008755       0.064249     -0.022069     0.079065    0.016016      -0.015596      0.001101    -0.290202     -0.187789           1.000000        -0.018306       -0.031080       0.024482    0.048130 -0.087492        0.145740     0.048614    0.098936      0.107965     -0.066754  0.177441  0.185756  0.170944\n",
      "guardian_mother   -0.048726  0.091562 -0.044450   -0.066130  -0.018076 -0.056527  0.012507  0.022349  0.042602 -0.093064 -0.006809  0.009374  0.005036  -0.052590 -0.030708   0.015464     0.017646  -0.070786    -0.034105   -0.109205       0.063294      0.123488    -0.038682    0.086263      -0.059257     -0.003512     0.004316      0.016315          -0.018306         1.000000       -0.397690      -0.018390   -0.034759  0.037643        0.041487     0.073914    0.080524     -0.024990     -0.017849 -0.005619  0.001851 -0.004415\n",
      "guardian_other     0.330353 -0.101123 -0.066684    0.090497   0.006440  0.234027 -0.067365  0.033823  0.018432  0.112437 -0.002456  0.008833  0.155654  -0.016982 -0.010358  -0.035192    -0.015673  -0.114559    -0.049186    0.086726      -0.087019     -0.051397    -0.049776    0.087079      -0.062630     -0.062930     0.023901     -0.071564          -0.031080        -0.397690        1.000000      -0.026798    0.050158  0.040941       -0.024076    -0.094132   -0.198100      0.023074      0.130019 -0.125517 -0.105238 -0.080729\n",
      "schoolsup_yes     -0.167841 -0.022168  0.023572   -0.044807   0.089316 -0.000745 -0.012038 -0.015611 -0.058124 -0.028076 -0.098275  0.022760 -0.059503  -0.123340 -0.111202   0.017956    -0.056405  -0.009456    -0.058235    0.040788       0.046361     -0.056772     0.070481   -0.014747      -0.055696      0.070951     0.052495      0.007306           0.024482        -0.018390       -0.026798       1.000000    0.075402  0.040512       -0.030246     0.017846    0.085355     -0.025942     -0.094310 -0.071779 -0.056624 -0.066405\n",
      "famsup_yes        -0.101894  0.120491  0.135191   -0.039289   0.143509 -0.006982  0.015228  0.003764  0.017262 -0.016844 -0.065605  0.018803  0.041980  -0.063720 -0.129467   0.005577    -0.039819   0.010203     0.043086   -0.091924       0.074613      0.028670     0.083770   -0.064231      -0.007044      0.026580     0.027275     -0.092220           0.048130        -0.034759        0.050158       0.075402    1.000000  0.094297       -0.007433     0.027799    0.085340      0.071891     -0.023398  0.038255  0.038141  0.059206\n",
      "paid_yes          -0.005458  0.113973  0.094628   -0.044842  -0.002314  0.069416  0.031937 -0.049574 -0.006683  0.051986  0.035682  0.063203 -0.035959  -0.007905  0.079300  -0.030483    -0.050253   0.015923     0.002863   -0.033171       0.045041     -0.006743    -0.013400    0.012374       0.001782     -0.032951     0.062376      0.034544          -0.087492         0.037643        0.040941       0.040512    0.094297  1.000000        0.065781     0.027566    0.024112      0.031823     -0.018309 -0.062784 -0.033925 -0.054898\n",
      "activities_yes    -0.054279  0.119354  0.079700   -0.033376   0.070080  0.000561  0.057597  0.150329  0.088582  0.022592  0.032824  0.013001 -0.015115  -0.088604  0.124707  -0.009278    -0.014790   0.101555     0.008277   -0.077004       0.060531      0.098696    -0.002723   -0.062991       0.035401      0.034036    -0.082974     -0.087820           0.145740         0.041487       -0.024076      -0.030246   -0.007433  0.065781        1.000000     0.039719    0.044908      0.082375      0.057517  0.080123  0.067154  0.059791\n",
      "nursery_yes       -0.021441  0.125951  0.074863   -0.011509   0.042630 -0.069241  0.041055 -0.007096  0.018679 -0.078376 -0.075748  0.001701 -0.040574   0.004659 -0.043603   0.018077     0.100686  -0.032724     0.036501   -0.087954       0.026858      0.076450     0.053120   -0.020451      -0.011243     -0.015223    -0.024062      0.002470           0.048614         0.073914       -0.094132       0.017846    0.027799  0.027566        0.039719     1.000000    0.042605     -0.007159     -0.022984  0.031172  0.039867  0.028752\n",
      "higher_yes        -0.265497  0.213896  0.191735   -0.071958   0.188256 -0.309400  0.048239 -0.102618 -0.069105 -0.131663 -0.084327  0.017290 -0.129891  -0.136112 -0.058134   0.076706     0.004523   0.022726     0.097475   -0.026252       0.042486      0.105923     0.039076   -0.019982       0.025007      0.061747     0.045657     -0.053244           0.098936         0.080524       -0.198100       0.085355    0.085340  0.024112        0.044908     0.042605    1.000000      0.070345     -0.099389  0.349030  0.331953  0.332172\n",
      "internet_yes       0.013115  0.266052  0.183483   -0.190826   0.037529 -0.095330  0.082214  0.063268  0.092869  0.042811  0.060651 -0.022792  0.067301  -0.240486  0.065911   0.175794     0.013357   0.059754     0.085946   -0.066857       0.149119      0.148069     0.006929    0.002857       0.049705      0.005990     0.066481     -0.049326           0.107965        -0.024990        0.023074      -0.025942    0.071891  0.031823        0.082375    -0.007159    0.070345      1.000000      0.034832  0.139931  0.147909  0.150025\n",
      "romantic_yes       0.178810 -0.030992 -0.067675    0.004751   0.033036  0.069901 -0.044920  0.027112 -0.000520  0.062042 -0.019971 -0.018025  0.079489   0.072241 -0.110144  -0.030939    -0.032936  -0.053828     0.016156    0.039095      -0.063447     -0.045922    -0.025398    0.005471      -0.018912      0.024321     0.000983      0.035453          -0.066754        -0.017849        0.130019      -0.094310   -0.023398 -0.018309        0.057517    -0.022984   -0.099389      0.034832      1.000000 -0.074973 -0.097937 -0.090583\n",
      "G1                -0.174322  0.260472  0.217501   -0.154120   0.260875 -0.384210  0.048795 -0.094497 -0.074053 -0.195171 -0.155649 -0.051647 -0.147149  -0.292626 -0.104109   0.157127     0.047230   0.015251     0.102689   -0.036684       0.039645      0.148925     0.045028   -0.015253      -0.024090      0.146338     0.051471     -0.090738           0.177441        -0.005619       -0.125517      -0.071779    0.038255 -0.062784        0.080123     0.031172    0.349030      0.139931     -0.074973  1.000000  0.864982  0.826387\n",
      "G2                -0.107119  0.264035  0.225139   -0.154489   0.240498 -0.385782  0.089588 -0.106678 -0.079469 -0.189480 -0.164852 -0.082179 -0.124745  -0.269776 -0.104005   0.154600     0.038891   0.018689     0.104420   -0.040108       0.026613      0.136419     0.045478   -0.010922      -0.042709      0.146767     0.040337     -0.096135           0.185756         0.001851       -0.105238      -0.056624    0.038141 -0.033925        0.067154     0.039867    0.331953      0.147909     -0.097937  0.864982  1.000000  0.918548\n",
      "G3                -0.106505  0.240151  0.211800   -0.127173   0.249789 -0.393316  0.063361 -0.122705 -0.087641 -0.204719 -0.176619 -0.098851 -0.091379  -0.284294 -0.129077   0.167637     0.045016  -0.000754     0.101244   -0.059251       0.038447      0.134910     0.039142   -0.005301      -0.053204      0.125916     0.046537     -0.132577           0.170944        -0.004415       -0.080729      -0.066405    0.059206 -0.054898        0.059791     0.028752    0.332172      0.150025     -0.090583  0.826387  0.918548  1.000000\n",
      "G1 Model - MSE: 6.41, R²: 0.23\n",
      "G2 Model - MSE: 7.79, R²: 0.21\n",
      "G3 Model - MSE: 8.32, R²: 0.25\n",
      "G1 Random Forest Model - MSE: 6.68, R²: 0.20\n",
      "G2 Random Forest Model - MSE: 7.75, R²: 0.21\n",
      "G3 Random Forest Model - MSE: 8.24, R²: 0.26\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Fetch the dataset\n",
    "student_performance = fetch_ucirepo(id=320)\n",
    "\n",
    "# Prepare the features and targets\n",
    "X = student_performance.data.features\n",
    "y = student_performance.data.targets\n",
    "\n",
    "# Create dummy variables\n",
    "X_dummies = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Define the target variables\n",
    "G1 = y['G1']\n",
    "G2 = y['G2']\n",
    "G3 = y['G3']\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = pd.concat([X_dummies, y], axis=1).corr()\n",
    "\n",
    "# Print the correlation matrix as text\n",
    "print(\"Matriz de Correlación:\")\n",
    "print(correlation_matrix.to_string())\n",
    "\n",
    "def fit_and_evaluate_model(target_variable, feature_data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_variable, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = Lasso(alpha=0.1) \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "# Store results for Lasso model\n",
    "results = {}\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    model, mse, r2 = fit_and_evaluate_model(target, X_dummies)\n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "# Optionally, try a Random Forest model as well\n",
    "def fit_random_forest(target_variable, feature_data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_variable, test_size=0.3, random_state=42)\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, mse, r2\n",
    "\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    model, mse, r2 = fit_random_forest(target, X_dummies)\n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Random Forest Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'Medu', 'Fedu', 'traveltime', 'studytime', 'failures', 'famrel',\n",
      "       'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences', 'school_MS',\n",
      "       'sex_M', 'address_U', 'famsize_LE3', 'Pstatus_T', 'Mjob_health',\n",
      "       'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_health',\n",
      "       'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_home',\n",
      "       'reason_other', 'reason_reputation', 'guardian_mother',\n",
      "       'guardian_other', 'schoolsup_yes', 'famsup_yes', 'paid_yes',\n",
      "       'activities_yes', 'nursery_yes', 'higher_yes', 'internet_yes',\n",
      "       'romantic_yes'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>...</th>\n",
       "      <th>guardian_mother</th>\n",
       "      <th>guardian_other</th>\n",
       "      <th>schoolsup_yes</th>\n",
       "      <th>famsup_yes</th>\n",
       "      <th>paid_yes</th>\n",
       "      <th>activities_yes</th>\n",
       "      <th>nursery_yes</th>\n",
       "      <th>higher_yes</th>\n",
       "      <th>internet_yes</th>\n",
       "      <th>romantic_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  \\\n",
       "0     18     4     4           2          2         0       4         3   \n",
       "1     17     1     1           1          2         0       5         3   \n",
       "2     15     1     1           1          2         0       4         3   \n",
       "3     15     4     2           1          3         0       3         2   \n",
       "4     16     3     3           1          2         0       4         3   \n",
       "..   ...   ...   ...         ...        ...       ...     ...       ...   \n",
       "644   19     2     3           1          3         1       5         4   \n",
       "645   18     3     1           1          2         0       4         3   \n",
       "646   18     1     1           2          2         0       1         1   \n",
       "647   17     3     1           2          1         0       2         4   \n",
       "648   18     3     2           3          1         0       4         4   \n",
       "\n",
       "     goout  Dalc  ...  guardian_mother  guardian_other  schoolsup_yes  \\\n",
       "0        4     1  ...             True           False           True   \n",
       "1        3     1  ...            False           False          False   \n",
       "2        2     2  ...             True           False           True   \n",
       "3        2     1  ...             True           False          False   \n",
       "4        2     1  ...            False           False          False   \n",
       "..     ...   ...  ...              ...             ...            ...   \n",
       "644      2     1  ...             True           False          False   \n",
       "645      4     1  ...             True           False          False   \n",
       "646      1     1  ...             True           False          False   \n",
       "647      5     3  ...             True           False          False   \n",
       "648      1     3  ...             True           False          False   \n",
       "\n",
       "     famsup_yes  paid_yes  activities_yes  nursery_yes  higher_yes  \\\n",
       "0         False     False           False         True        True   \n",
       "1          True     False           False        False        True   \n",
       "2         False     False           False         True        True   \n",
       "3          True     False            True         True        True   \n",
       "4          True     False           False         True        True   \n",
       "..          ...       ...             ...          ...         ...   \n",
       "644       False     False            True        False        True   \n",
       "645        True     False           False         True        True   \n",
       "646       False     False            True         True        True   \n",
       "647       False     False           False        False        True   \n",
       "648       False     False           False        False        True   \n",
       "\n",
       "     internet_yes  romantic_yes  \n",
       "0           False         False  \n",
       "1            True         False  \n",
       "2            True         False  \n",
       "3            True          True  \n",
       "4           False         False  \n",
       "..            ...           ...  \n",
       "644          True         False  \n",
       "645          True         False  \n",
       "646         False         False  \n",
       "647          True         False  \n",
       "648          True         False  \n",
       "\n",
       "[649 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G1 Model - MSE: 6.61, R²: 0.21\n",
      "G2 Model - MSE: 7.99, R²: 0.19\n",
      "G3 Model - MSE: 8.46, R²: 0.23\n",
      "G1 Random Forest Model - MSE: 6.70, R²: 0.20\n",
      "G2 Random Forest Model - MSE: 7.68, R²: 0.22\n",
      "G3 Random Forest Model - MSE: 8.74, R²: 0.21\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Cargar el dataset de estudiantes\n",
    "student_performance = fetch_ucirepo(id=320)\n",
    "\n",
    "# Obtener características y objetivos\n",
    "X = student_performance.data.features\n",
    "y = student_performance.data.targets\n",
    "\n",
    "# Convertir variables categóricas en variables dummy\n",
    "X_dummies = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Definir las variables objetivo\n",
    "G1 = y['G1']\n",
    "G2 = y['G2']\n",
    "G3 = y['G3']\n",
    "print(X_dummies.columns)\n",
    "# Eliminar columnas irrelevantes\n",
    "columns_to_drop = ['school_MS', 'sex_M', 'address', 'famsize', 'Pstatus', 'reason', \n",
    "                   'guardian', 'school_sup', 'famsup', 'paid', 'activities', \n",
    "                   'nursery', 'higher', 'internet', 'romantic']\n",
    "\n",
    "X_dummies_cleaned = X_dummies.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "display(X_dummies_cleaned)\n",
    "# Almacenar resultados\n",
    "results = {}\n",
    "\n",
    "# Entrenar y evaluar el modelo Lasso\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dummies_cleaned, target, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = Lasso(alpha=0.1) \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "# Entrenar y evaluar el modelo Random Forest\n",
    "for g, target in zip(['G1', 'G2', 'G3'], [G1, G2, G3]):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_dummies_cleaned, target, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results[g] = {'model': model, 'MSE': mse, 'R²': r2}\n",
    "    print(f\"{g} Random Forest Model - MSE: {mse:.2f}, R²: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = []\n",
    "for i in range(7, len(X_train.columns) + 1):\n",
    "    all_combinations += list(combinations(X_train.columns, i))\n",
    "\n",
    "model_results = {}\n",
    "for combination in all_combinations:\n",
    "    combination_name = ', '.join(combination)\n",
    "    X_train_subset = X_train[list(combination)]\n",
    "    X_test_subset = X_test[list(combination)]\n",
    "    model_results[combination_name] = {}\n",
    "    for model_name, model in models.items():\n",
    "        reg_pipeline = Pipeline([\n",
    "            (\"numerical_imputer\", SimpleImputer(strategy='mean')),\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "        reg_pipeline.fit(X_train_subset, y_train)\n",
    "        y_pred = reg_pipeline.predict(X_test_subset)\n",
    "        test_score = r2_score(y_test, y_pred)\n",
    "        model_results[combination_name][model_name] = test_score\n",
    "results = pd.DataFrame(model_results)\n",
    "results.index.name = 'Modelo'\n",
    "results.columns.name = 'Combinación de Características'\n",
    "results = results.stack().reset_index()\n",
    "results.columns = ['Modelo', 'Combinación de Características', 'Puntaje R^2']\n",
    "results.sort_values('Puntaje R^2', ascending=False).head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
